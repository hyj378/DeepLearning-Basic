
(1주차) 11월 12일 / 11월 15일 까지

섹션 0. 오리엔테이션
수업 소개와 개요	[비디오][슬라이드]
00:10:00

섹션 1. 머신러닝의 개념과 용어
기본적인 Machine Learnnig 의 용어와 개념 설명	미리보기	
00:12:00
TensorFlow의 설치및 기본적인 operations (new)		
00:17:00

섹션 2. Linear Regression 의 개념
Linear Regression의 Hypothesis 와 cost		
00:13:00
Tensorflow로 간단한 linear regression을 구현 (new)		
00:15:00

섹션 3. Linear Regression cost 함수 최소화
Linear Regression의 cost 최소화 알고리즘의 원리		
00:16:00
Linear Regression 의 cost 최소화의 TensorFlow 구현(new)		
00:15:00

섹션 4. 여러개의 입력(feature)의 Linear Regression
multi-variable linear regression (new)		
00:17:00
lab 04-1: multi-variable linear regression을 TensorFlow에서 구현하기	미리보기	
00:08:00
lab 04-2: TensorFlow로 파일에서 데이타 읽어오기 (new)		
00:06:00

=========================
(2주차) 11월 19일 / 11월 22일 까지

섹션 5. Logistic (Regression) Classification
Logistic Classification의 가설 함수 정의		
00:15:00
Logistic Regression의 cost 함수 설명		
00:14:00
TensorFlow로 Logistic Classification의 구현하기(new)		
00:15:00


섹션 6. Softmax Regression (Multinomial Logistic Regression)
Multinomial 개념 소개		
00:10:00
Cost 함수 소개		
00:15:00
lab 06-1: TensorFlow로 Softmax Classification의 구현하기 (new)		
00:12:00
lab 06-2: TensorFlow로 Fancy Softmax Classification의 구현하기 (new)		
00:16:00


섹션 7. ML의 실용과 몇가지 팁
학습 rate, Overfitting, 그리고 일반화 (Regularization)		
00:14:00
Training/Testing 데이타 셋		
00:09:00
lab 07-1: training/test dataset, learning rate, normalization (new)		
00:11:00
lab 07-2: Meet MNIST Dataset (new)		
00:13:00


=========================
(3주차) 11월 26일 / 11월 29일 

섹션 8. 딥러닝의 기본 개념과, 문제, 그리고 해결
딥러닝의 기본 개념: 시작과 XOR 문제		
00:17:00
딥러닝의 기본 개념2: Back-propagation 과 2006/2007 ‘딥’의 출현		
00:12:00
Lab : Tensor Manipulation (new)		
00:26:00


섹션 9. Neural Network 1: XOR 문제와 학습방법, Backpropagation
XOR 문제 딥러닝으로 풀기		
00:15:00
특별편: 10분안에 미분 정리하기		
00:09:00
딥넷트웍 학습 시키기 (backpropagation)		
00:18:00
Lab 9-1: XOR을 위한 텐스플로우 딥넷트웍 (new)		
00:12:00
Lab 9-2: Tensor Board로 딥네트웍 들여다보기 (new)		
00:12:00
Neural Network 2: ReLU and 초기값 정하기 (2006/2007 breakthrough)
XSigmoid 보다 ReLU가 더 좋아		
00:17:00
Weight 초기화 잘해보자		
00:12:00
Dropout 과 앙상블		
00:10:00
레고처렴 넷트웍 모듈을 마음껏 쌓아 보자		
00:05:00
Lab 10: 딥러닝으로 MNIST 98%이상 해보기(new)		
00:14:00

=========================

(4주차) 12월 3일 / 12월 6일 

섹션 11. Convolutional Neural Networks
ConvNet의 Conv 레이어 만들기	미리보기	
00:16:00
ConvNet Max pooling 과 Full Network	미리보기	
00:05:00
ConvNet의 활용 예	미리보기	
00:12:00
실습1: TensorFlow CNN 의 기본		
00:16:00
실습2: TensorFlow로 구현하자 (MNIST 99%)		
00:12:00
실습3: Class, tf.layers, Ensemble (MNIST 99.5%)		
00:10:00


=========================

(5주차) 12월 24일 / 12월 27일까지

섹션 12. Recurrent Neural Network
NN의 꽃 RNN 이야기	미리보기	
00:19:00
Lab 12-1 RNN – Basic (new)	미리보기	
00:12:00
Lab 12-2 RNN – Hi Hello Training (new)	미리보기	
00:15:00
Lab 12-3 : Long Sequence RNN (new)		
00:00:00
Lab12-4: Stacked RNN + Softmax Layer (new)		
00:11:00
Lab12-5: Dynamic RNN (new)		
00:04:00
Lab12-6: RNN with Time Series Data (new)		
00:10:00

(부록) 5주차에 


섹션 13. Deep Deep Network AWS 에서 GPU와 돌려보기 (powered bt AWS)
powered by AWS		
00:18:00
섹션 14. AWS 에서 저렴하게 Spot Instance 를 터미네이션 걱정없이 사용하기
AWS에서 저렴하게 Spot Instance를 터미네이션 걱정없이 사용하기	미리보기	
00:18:00
섹션 15. Google Cloud ML을 이용해 TensorFlow 실행하기
Google Cloud ML with Examples 1


